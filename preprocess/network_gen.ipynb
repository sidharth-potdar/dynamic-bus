{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "%matplotlib inline \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn \n",
    "from scipy.stats import kstest \n",
    "import progressbar\n",
    "import json \n",
    "import gc\n",
    "from shapely.geometry import GeometryCollection, shape\n",
    "import multiprocessing \n",
    "import ctypes\n",
    "import pickle\n",
    "from collections import deque \n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading census data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading census data...\") \n",
    "with open(\"../data/washington_DC_censustracts.json\", 'r') as f: \n",
    "    features =  json.load(f)['features']\n",
    "\n",
    "col = GeometryCollection([shape(feature[\"geometry\"]).buffer(0) for feature in features])\n",
    "\n",
    "# divide into four equal segments \n",
    "all_values = [] \n",
    "for i in range(len(col)): \n",
    "    for j in range(i + 1, len(col)): \n",
    "        all_values.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = 3\n",
    "chunk_size = len(all_values) // processes + 1\n",
    "segments = [all_values[chunk_size * i:chunk_size * (i + 1)] for i in range(processes)]\n",
    "value = multiprocessing.Value(ctypes.c_ulong, lock=False)\n",
    "lock = multiprocessing.Lock()\n",
    "queue = multiprocessing.Queue()\n",
    "args = [(segment, col, value, features) for segment in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_function(segment, col, counter, features): \n",
    "    c = 0 \n",
    "    edge_set = set() \n",
    "    for i, j in segment: \n",
    "        c += 1\n",
    "        if c % 10000 == 0: \n",
    "            res = lock.acquire(timeout=10) \n",
    "            if res: \n",
    "                counter.value += c \n",
    "                queue.put(tuple(edge_set))\n",
    "                lock.release() \n",
    "                c = 0  \n",
    "                edge_set = set() \n",
    "        if i != j: \n",
    "            if col[i].touches(col[j]): \n",
    "                t = (features[i]['properties']['MOVEMENT_ID'], features[j]['properties']['MOVEMENT_ID'])\n",
    "                edge_set.add(t)\n",
    "                edge_set.add((t[1], t[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Adjacencies...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Adjacencies...\")\n",
    "ps = []\n",
    "value.value = 0 \n",
    "for i in range(processes): \n",
    "    ps.append(multiprocessing.Process(target=adj_function, args=args[i]))\n",
    "    ps[-1].start() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|#################################       |130000 of 155403   ETA:   0:00:00 83%"
     ]
    }
   ],
   "source": [
    "widgets = [\n",
    "    progressbar.Bar(),\n",
    "    progressbar.SimpleProgress(),\n",
    "    \"   \",\n",
    "    progressbar.ETA(), \n",
    "    progressbar.Percentage()]\n",
    "bar = progressbar.ProgressBar(max_value=len(all_values), widgets=widgets)\n",
    "l = [] \n",
    "while all((p.is_alive() for p in ps)):\n",
    "    bar.update(value.value)\n",
    "    if not queue.empty(): \n",
    "        l.append(queue.get()) \n",
    "\n",
    "for p in ps: \n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not queue.empty(): \n",
    "    l.append(queue.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = [] \n",
    "for k in l: \n",
    "    all_edges += k \n",
    "all_edges = set(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in Uber Data...\n",
      "Filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajshrimali/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceid</th>\n",
       "      <th>dstid</th>\n",
       "      <th>hod</th>\n",
       "      <th>mean_travel_time</th>\n",
       "      <th>standard_deviation_travel_time</th>\n",
       "      <th>geometric_mean_travel_time</th>\n",
       "      <th>geometric_standard_deviation_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>403</td>\n",
       "      <td>398</td>\n",
       "      <td>8</td>\n",
       "      <td>167.15</td>\n",
       "      <td>134.52</td>\n",
       "      <td>125.59</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>540.13</td>\n",
       "      <td>266.69</td>\n",
       "      <td>495.31</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408</td>\n",
       "      <td>348</td>\n",
       "      <td>8</td>\n",
       "      <td>2075.65</td>\n",
       "      <td>338.14</td>\n",
       "      <td>2048.54</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130</td>\n",
       "      <td>368</td>\n",
       "      <td>7</td>\n",
       "      <td>1560.50</td>\n",
       "      <td>312.76</td>\n",
       "      <td>1532.50</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>429</td>\n",
       "      <td>138</td>\n",
       "      <td>8</td>\n",
       "      <td>1478.86</td>\n",
       "      <td>586.25</td>\n",
       "      <td>1378.72</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sourceid  dstid  hod  mean_travel_time  standard_deviation_travel_time  \\\n",
       "0       403    398    8            167.15                          134.52   \n",
       "1       156    108    7            540.13                          266.69   \n",
       "2       408    348    8           2075.65                          338.14   \n",
       "3       130    368    7           1560.50                          312.76   \n",
       "4       429    138    8           1478.86                          586.25   \n",
       "\n",
       "   geometric_mean_travel_time  geometric_standard_deviation_travel_time  \n",
       "0                      125.59                                      2.44  \n",
       "1                      495.31                                      1.48  \n",
       "2                     2048.54                                      1.18  \n",
       "3                     1532.50                                      1.20  \n",
       "4                     1378.72                                      1.44  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reading in Uber Data...\")\n",
    "df = pd.read_csv(\"../data/washington_DC-censustracts-2019-3-OnlyWeekdays-HourlyAggregate.csv\", low_memory=False)\n",
    "print(\"Filtering...\")\n",
    "RUSH_HOUR_START = 6 \n",
    "RUSH_HOUR_END = 10 \n",
    "filtered_df = df[df['hod'] <= RUSH_HOUR_END][df['hod'] >= RUSH_HOUR_START]\n",
    "del df \n",
    "filtered_df = filtered_df.reset_index().drop('index', axis=1)\n",
    "gc.collect() \n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = filtered_df.loc[:, [\"sourceid\", \"dstid\"]]\n",
    "all_values = np.hstack([k.index.to_numpy().reshape(-1,1), k.to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% (712195 of 730693) |############### | Elapsed Time: 0:00:03 ETA:   0:00:00"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar(max_value=all_values.shape[0])\n",
    "drop_list = deque() \n",
    "for row in all_values: \n",
    "    if (str(row[1]), str(row[2])) not in all_edges: \n",
    "        drop_list.append(row[0])\n",
    "    bar.update(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop(drop_list).reset_index().drop('index', axis=1)\n",
    "filtered_df['sourceid'] = filtered_df['sourceid'].astype(str) \n",
    "filtered_df['dstid'] = filtered_df['dstid'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Graph...\n"
     ]
    }
   ],
   "source": [
    "# build graph \n",
    "print(\"Building Graph...\")\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Verifying Connectivity\")\n",
    "nx.is_weakly_connected(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 558) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Centroids...\n",
      "Ignoring 2 regions\n"
     ]
    }
   ],
   "source": [
    "# go over all polygons and calculate their centroids \n",
    "print(\"Finding Centroids...\")\n",
    "node_centroid_iter = ((features[i]['properties']['MOVEMENT_ID'], col[i].centroid.coords[0]) for i in range(len(col)))\n",
    "bar = progressbar.ProgressBar(max_value=len(col))\n",
    "disconnected_set = set()\n",
    "for i, (id_, coords) in enumerate(node_centroid_iter): \n",
    "    if id_ in graph.nodes: \n",
    "        graph.nodes[id_][\"loc\"] = coords\n",
    "    else: \n",
    "        disconnected_set.add((i, id_))\n",
    "    bar.update(i) \n",
    "print(\"Ignoring\", len(disconnected_set), \"regions\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% (408 of 16105) |                    | Elapsed Time: 0:00:00 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating Edges with Travel Times...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16105 of 16105) |##################| Elapsed Time: 0:00:02 Time:  0:00:02\n"
     ]
    }
   ],
   "source": [
    "print(\"Associating Edges with Travel Times...\")\n",
    "with progressbar.ProgressBar(max_value=filtered_df.shape[0]) as bar: \n",
    "    for id_, row in filtered_df.iterrows(): \n",
    "        bar.update(id_)\n",
    "        if (row['hod'] >= RUSH_HOUR_START and row['hod'] <= RUSH_HOUR_END): \n",
    "            graph[row['sourceid']][row['dstid']][row['hod']] = {'mean': row['mean_travel_time'], \n",
    "                                                                'stdev': row['standard_deviation_travel_time'],\n",
    "                                                                'gmean': row['geometric_mean_travel_time'],\n",
    "                                                                'gstdev': row['geometric_standard_deviation_travel_time']}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for missing information...\n",
      "Found edge ('535', '427') missing 5 HODs. Filled in with distribution (median).\n",
      "Found 1 edge(s) missing data in total.\n"
     ]
    }
   ],
   "source": [
    "# get dist of each HOD travel time\n",
    "# find missing edges\n",
    "print(\"Searching for missing information...\")\n",
    "edges_missing_data = [] \n",
    "for edge in graph.edges: \n",
    "    hods_satisfied = graph[edge[0]][edge[1]].keys() \n",
    "    c = 0\n",
    "    for hod in range(RUSH_HOUR_START, RUSH_HOUR_END + 1): \n",
    "        if hod not in hods_satisfied:\n",
    "            # get means all around. \n",
    "            mean_df = filtered_df[filtered_df['hod'] == hod].median(axis=0) \n",
    "            graph[edge[0]][edge[1]][hod] = {\n",
    "                \"mean\": mean_df['mean_travel_time'], \n",
    "                \"stdev\": mean_df['standard_deviation_travel_time'], \n",
    "                \"gmean\": mean_df[\"geometric_mean_travel_time\"], \n",
    "                \"gstdev\": mean_df[\"geometric_standard_deviation_travel_time\"]\n",
    "            }\n",
    "            c += 1\n",
    "    if c != 0: \n",
    "        print(\"Found edge\", edge, \"missing\", c, \"HODs. Filled in with distribution (median).\")\n",
    "        edges_missing_data.append(edge) \n",
    "print(\"Found\", len(edges_missing_data), \"edge(s) missing data in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Formats...\n"
     ]
    }
   ],
   "source": [
    "# write to our format.\n",
    "# template: node: [(x, y), [(edge, weight)]]\n",
    "print(\"Converting Formats...\")\n",
    "graph_dict = {}\n",
    "dist_dict = {}\n",
    "for node in graph.nodes: \n",
    "    neighbors = graph.neighbors(node) \n",
    "    location = graph.nodes[node]['loc']\n",
    "    # use geometric mean std for now \n",
    "    edges = []\n",
    "    for neighbor in neighbors: \n",
    "        s = 0\n",
    "        for hod in range(RUSH_HOUR_START, RUSH_HOUR_END + 1):\n",
    "            s += graph[node][neighbor][hod]['gmean'] / (RUSH_HOUR_END - RUSH_HOUR_START + 1)\n",
    "        edges.append((neighbor, s))\n",
    "        dist_dict[(node, neighbor)] = deepcopy(graph[node][neighbor])\n",
    "    graph_dict[node] = (location, tuple(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving...\")\n",
    "with open(\"../pickles/graph.pypkle\", 'wb') as f: \n",
    "    pickle.dump((graph_dict, dist_dict), f)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda38abeda7573f4187b27693fd95651d92"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
